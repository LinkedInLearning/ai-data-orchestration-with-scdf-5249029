The details to install ollama can be fought here.

https://ollama.com/download


To start it type

```shell
ollama serve
```
in a terminal


You can pull the llama3 model to you local environment using the ollama run command with the name of the model

```shell
ollama run llama3
```
